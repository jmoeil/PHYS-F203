\documentclass[../notesdecours.tex]{subfiles}

\begin{document}
    
\chapter{Notions mathématiques}

\paragraph{} Dans ce chapitre, nous allons rapidement passer en revue plusieurs notions de maths, 
plus particulièrement d'analyse, qui apparaissent dans le cours de Mécanique Quantique, 
afin de vous aider dans la compréhension de certains passage de calculs. \\
Nous allons commencer par de brefs rappels de CDI2 sur les séries et transformées de Fourier, 
pour ensuite embrayer sur la notion de distribution, qui est certainement neuve dans votre parcours,
mais cela permettra plus tard de justifier l'utilisation de distribution pour décrire les fonctions d'onde. \\

\section{Séries de Fourier}
Considérons $f$ une fonction T-périodique ; \\

\begin{definition}[coefficients de Fourier]
    On définit ses coefficients de Fourier (exponentiels) par la formule : 
\begin{equation}
c_n = \frac{1}{T} \int^{T/2}_{-T/2} dx f(x)e^{-2\pi i(\frac{n}{T})x} \\
\end{equation}
\end{definition}

\begin{definition}[Série de Fourier]
    On appelle la série de Fourier associée à $f$, la série de fonctions qui est telle que 
$\forall n \in \mathbb{N}$, la somme partielle de cette série $S_n(f)$ est donnée par :
\begin{equation}
    \forall n\in \mathbb{N} ; \quad \forall x \in \mathbb{R} ;  \quad S_n(f)(x) = \sum_{k=-n}^{n} c_k(f) e^{2\pi i \left( \frac{k}{T} \right) x} \\
\end{equation}
\end{definition}

\begin{theorem}[Théromème de Dirichlet]
    Le théorème de Dirichlet (global) nous assure que la série de Fourier de $f$ converge uniformément 
vers la fonction $f$ sur $\mathbb{R}$, ainsi nous pouvons écrire :  
\begin{equation}
    \forall x \in \mathbb{R} ; \quad f(x) = \sum_{k = -\infty}^{+\infty}c_ne^{2\pi i (\frac{k}{T})x} \\
\end{equation}
Notons que nous pouvons appliquer ce théorème car en physique, nous ne considérons en général que des fonctions très lisses (de classe \textit{C}$^{\infty}$).
\end{theorem}



\section{Transformées de Fourier}

Considérons une fonction $f$ (dans le cours de CDI2, nous faisons l'hypothèse que la fonction 
appartient à la classe de Schwartz, mais en réalité, la transformée de Fourier et ses propriétés se généralisent 
à des fonctions bien moins lisses). \\

\begin{definition}[Transformée de Fourier]
    La fonction  $\mathcal{F}(f)$, que l'on note aussi ici $\hat{f}(k)$, est la transformée 
    de Fourier de la fonction $f$, et est définie par : 
\begin{equation}
\hat{f}(k) = \mathcal{F}(f) = \frac{1}{\sqrt{2 \pi}} \int_{-\infty}^{+\infty} dx f(x) e^{-ikx}
\end{equation}
\end{definition}

\begin{theorem}[Inversion de la transformée de Fourier] 
    $\forall x \in \mathbb{R}$, on a $\mathcal{F}(\mathcal{G}(f))(x) = f(x)$ ou $\mathcal{G}(\mathcal{F}(f))(x) = f(x)$, 
    où $\mathcal{G}(f) = \mathcal{F}^{-1}(f)$ est l'inverse de la transformée de fourier de $f$. \\
    Ceci s'exprime encore comme : 
    \begin{equation}
        f(x) = \mathcal{G}(\hat{f})(x) = \frac{1}{\sqrt{2 \pi}} \int_{-\infty}^{+\infty} dk\hat{f}(k) e^{ikx}
    \end{equation}
Remarquons que $\mathcal{G}(f)(k)$ n'est rien d'autre que $\mathcal{F}(f)(-k)$
\end{theorem}

\begin{remark}
Si $f$ est à support borné et $ \left[ -\frac{T}{2},\frac{T}{2} \right] $ est un intervalle contenant le support, alors sa transformée de Fourier est 
en fait à support infini, et l'on peut écrire les coefficients de Fourier sous la forme : 
    \begin{equation}
    c_n = \frac{\sqrt{2\pi}}{T}\hat{f} \left( \frac{2\pi n}{T} \right) 
    \end{equation}
En effet, nous avons alors que :
    \begin{align}
\rightarrow f(x) &= \sum_{n = -\infty}^{+\infty} \frac{\sqrt{2\pi}}{T}\hat{f} \left( \frac{2\pi n}{T} \right) e^{i\frac{2\pi n}{T}x}\\
&= \sum_{n = -\infty}^{+\infty} \hat{f}(k_n)\frac{e^{ik_nx}}{\sqrt{2\pi}} \Delta k \quad \mbox{(où : $k_n \equiv \frac{2\pi n}{T}$ et $\Delta k \equiv \frac{2\pi}{T}$)}\\
&= \int_{-\infty}^{+\infty} dk \hat{f}(k) \frac{e^{ikx}}{\sqrt{2\pi}}
    \end{align}
La transformée de Fourier de $f$ est donc bien à support infini. 
\end{remark}

\begin{Property}
Mentionnons les différentes propriétés que suivent la transformée de Fourier. \\
On considère les fonctions $f$, $g$ et $h$ ; 
\begin{itemize}[label = \textbullet]
\item \textit{Linéarité} : Si $h(x) = af(x) + bg(x)$, alors $\hat{h}(k) = a\hat{f}(k) + b\hat{g}(k)$ ;
\item \textit{Translation} : Si $h(x) = f(x-x_0)$, alors $\hat{h}(k) = e^{-ikx_0}\hat{f}(k)$ ; 
\item \textit{Modulation} : Si $h(x) = f(x) e^{ik_0 x}$, alors $\hat{h}(k) = \hat{f}(k-k_0)$ ;
\item \textit{Changement d'échelle} : Si $h(x) = f(ax)$, alors $\hat{h}(k) = \frac{1}{a}\hat{f}(\frac{k}{a})$.
\item \textit{Conjugaison} : Si $h(x) = \overline{f(x)}$, alors $\hat{h}(k) = \overline{\hat{f}(-k)}$. \\
Notons que si $f(x)$ est réel, alors $\hat{f}(-k) = \overline{\hat{f}(k)}$ ;
\item $\hat{f}(0) = \int_{-\infty}^{+\infty} dxf(x)$.
\item \textit{Dérivation} : $\widehat{f \textquotesingle (k)} =ik \hat{f}(k)$. Cela se généralise à la dérivée $n^{\mbox{ième}}$ : \\
$\widehat{f^n (k)} = (ik)^n \hat{f}(k)$. 
\item Si $f(x)x^n$ est intégrable, alors $\hat{f}(k)$ est n-fois dérivable ; 
\item Si $f(x)$ est n-fois dérivale, alors $\hat{f}(k)k^n$ est intégrable ; 
\item Soit $S$ l'espace des fonctions \textit{C}$^{\infty}$ à décroissance rapide (tel que $fx^n$ est intégrable $\forall n$), alors $\mathcal{F}(S) = S$. 
Autrement dit, $S$ est stable par la transformée de Fourier ;
\item \textit{Transformée de Fourier d'une convolution} : Si $h(x) = (f \star h)(x) = \int dy f(y)g(x-y)$, \\
alors $\hat{h}(k) = \hat{f}(k)\ti\hat{g}(k)$ (à un facteur près) ;
\item \textit{Identité de Plancherel} : $\int dx \abs{f(x)}^2 = \int dk \abs{\hat{f}(k)}^2$ ; 
\item \textit{Identité de Plancherel polarisée} : $\int dx f(x)\overline{g(x)} = \int dk \hat{f}(k)\overline{\hat{g}(k)}$ 
\end{itemize}
\end{Property}

\section{Distributions}
Les distributions sont des objets mathématiques qui ont pour but de généraliser la notion de fonction. \\
Ce ne sont pas des fonctions à proprement parlé, mais sont définis en laissant la possibilité de faire des opérations
qui nous sont familières, telles que la dérivation, la transformée de Fourier, la convolution; etc... \\

\subsection{Espace de fonctions test}

Définissons ici les deux ensembles suivants: 
\begin{enumerate}
    \item $D = \left\{ \mbox{ fonctioncs \textit{C}$^{\infty}$ à support compact } \right\}$ ; cet ensemble, muni d'une certaine structure, est ce qu'on appelle l'\textbf{espace des fonctions test}.\\ 
    Les distributions agissent sur des fonctions test, et l'on note l'ensemble des distributions $D \textquotesingle$. \\
    \item $S = \left\{ \mbox{ fonctions \textit{C}$^{\infty}$ à décroissance rapide } \right\}$ ; c'est un ensemble de fonctions qui décroissent plus vite que $\frac{1}{P}$ pour n'importe quel polynôme $P$. \\
    Les distributions agissant sur ces fonctions forment un ensemble que l'on appelle l'ensemble des \textbf{distributions tempérées}, et que l'on note $S \textquotesingle$. \\
    Notons que la densité de $D$ dans $S$ fait que l'ensemble des distributions tempérées $S \textquotesingle$ est inclu dans l'ensemble des distributions $D \textquotesingle$ ;
    de ce fait, nous pourrons également parler de fonctions test pour les éléments de cet ensemble $S$ puisque les fonctions test sont définis comme des fonctions sur lesquelles agissent les distributions. 
\end{enumerate}

\paragraph{} Il se trouve que l'espace des fonctions test est constitué des ensembles que nous venons de définir, 
et doit être muni d'une structure afin de répondre à la définition d'un espace. 
Une notion de continuité/topologie doit dès lors être imposée sur les fonctions test, et s'exprime comme suit :
\begin{equation}
\varphi_k \rightarrow \varphi \iff (\partial_x^{(\alpha)} \varphi_k) \xrightarrow[\forall \alpha]{CVU} (\partial_x^{(\alpha)}\varphi)
\end{equation}
où CVU $\equiv$ convergence uniforme.

\subsection{Distributions}
\begin{description}
    \item [Définition :] Comment est en fait défini une distribution $T$ ? \\
    C'est une forme linéaire, continue sur l'espace des fonctions test, tel que 
    \begin{align*}
        T : \left( 
        \begin{array}{lll}
            D \quad \rightarrow \quad \mathbb{R} \\
            \varphi \quad \rightarrow \quad <T, \varphi>
        \end{array} \right)
    \end{align*}
    Nous pouvons également dire que les distributions $D \textquotesingle$ et $S \textquotesingle$ sont respectivement le dual de $D$ et de $S$. \\
    \item [Remarque :]
    \begin{itemize}[label = \textbullet]
        \item Si $\varphi_k \rightarrow \varphi$, alors $<T, \varphi_k> \mbox{ } \rightarrow \mbox{ } <T, \varphi>$ ;
        \item Si $T$ est une distribution et $\varphi$ une fonction test $\in D$, alors nous pouvons également noter le nombre $<T, \varphi>$ comme $T(\varphi)$. 
    \end{itemize}
    \item [Exemples :] Donnons maintenant 2 exemples de distributions : 
    \begin{enumerate}
        \item Soit $f : \mathbb{R} \rightarrow \mathbb{R}$ une fonction intégrable ; \\
        Alors on peut définir la distribution $T_f$ telle que : \\
        \begin{equation}
            T_f : \varphi \mbox{ } \rightarrow \mbox{ } <T_f, \varphi> = \int_{\mathbb{R}} dx f(x) \varphi(x)
        \end{equation}
        \textit{PS : L'application linéaire continue étant injective, on peut confondre $f$ et $T_f$}
        \item Le "delta de Dirac", que vous avez déjà peut-être rencontré, est en effet un distribution, et est défini comme ceci : \\
        \begin{equation}
        \label{delta de dirac}
            \delta : \varphi \mbox{ } \rightarrow \mbox{ } <\delta, \varphi> = \int_{\mathbb{R}} \delta(x) \varphi(x)dx = \varphi(0)
        \end{equation}
        \end{enumerate}
\end{description}

\subsection{Opérations sur les distributions}

\begin{description}
    \item [Dérivée d'une distribution :] En notant abusivement $T \textquotesingle$ pour exprimer $T_{f \mbox{\textquotesingle}}$, on peut définir la dérivation d'une distribution de la manière suivante : \\
    $<T \mbox{\textquotesingle} , \varphi> \mbox{ } = \mbox{ } <T, -\varphi \mbox{\textquotesingle}> $ \\
    En effet, en reprenant le premier exemple de distribution avec $f$ une fonction intégrable sur $\mathbb{R}$ et $T_f(\varphi) = \int_{\mathbb{R}} dx f(x) \varphi(x)$, 
    et en faisant une intégration par partie, on voit que : \\
    \begin{align}
        \int_{\mathbb{R}} dx f \mbox{\textquotesingle} (x) \varphi(x) &= \left[ f(x) \varphi(x) \right]_{\mathbb{R}} - \int_{\mathbb{R}} dx f(x) \varphi \mbox{\textquotesingle} (x) \notag \\
        \implies <T_{f \mbox{\textquotesingle}}, \varphi> &= <T, - \varphi \mbox{\textquotesingle}> \quad \mbox{(car $f(x) \varphi(x)$ s'annule en $\pm \infty$ ($\varphi$ étant une fonction test)) }\notag 
    \end{align}
    Donnons un exemple d'utilité de cette propriété : \\
    Considérons la fonction de Heaviside, également appelée fonction indicatrice de $\mathbb{R}^+$, discontinue en $0$, définie comme : 
    \begin{align}
    \label{fonction de Heaviside}
        \theta (x) &= \left\lbrace \begin{array}{lll}
                1 \quad \mbox{ si $x>0$} \\
                0 \quad \mbox{ si $x<0$}
                \end{array}\right. \notag \\
        \theta \mbox{\textquotesingle} (x) &= \delta (x)
    \end{align}
    Notons que la valeur en $0$, $\theta (0)$, n'a pas d'importance car la fonction apparaît le plus souvent dans une intégrale. \\
    Sa valeur est même en général arbitraire, et il arrive souvent de poser que $\theta (0) = \frac{1}{2}$ pour avoir que la fonction soit symétrique. \\
    Montrons à présent qu'il possible d'obtenir l'expression de la dérivée de la fonction de Heaviside \ref{fonction de Heaviside} grâce à la règle de dérivation au sens des distributions.  \\
    En effet, par cette dernière règle, nous avons que : 
    \begin{align}
        <\theta \mbox{\textquotesingle}, \phi> &= -<\theta, \phi \mbox{\textquotesingle}> \quad \mbox{(où $\phi$ est une fonction test)} \notag \\
        \implies <\theta \mbox{\textquotesingle}, \phi> &= - \int_{\mathbb{R}} \theta(x) \phi \mbox{\textquotesingle}(x) \notag \\
        &= - \int_0^{+ \infty} \phi \mbox{\textquotesingle}(x) \quad \mbox{ (par définition de la fonction $\theta(x)$)} \notag 
    \end{align}
    Par le théorème fondamental de l'analyse, $\phi(x)$ est une primitive de $\phi \mbox{\textquotesingle} (x)$. Ainsi, 
    \begin{equation} 
        <\theta \mbox{\textquotesingle}, \phi> = - \lim_{x \to +\infty} \phi(x) + \phi(0) = \phi(0) \quad \mbox{car $\phi(x) \to 0$ lorsque $x \to +\infty$ (fonction test)}
    \end{equation} 
    Or, par \ref{delta de dirac} (définition du delta de Dirac), on en déduit que : 
    \begin{align}
        <\theta \mbox{\textquotesingle}, \phi> &= \phi(0) \notag \\ 
        \iff \theta \mbox{\textquotesingle} (x) &= \delta (x)
    \end{align}
    \item [Multiplication d'une distribution par une fonction test :] $< T\phi, \varphi > \mbox{ } = \mbox{ } <T, \varphi \phi>$ \\
    \textit{Note importante : }Nous ne pouvons pas multiplier les distributions entre-elles.
\end{description}

\subsection{Théorèmes de structure}

\begin{description}
    \item[Structure locale :] Localement, une distribution est égale à la dérivée $\alpha^{\mbox{\small{ième}}}$ d'une fonction continue (par exemple, la fonction $\delta(x)$ peut être exprimée comme la dérivée seconde d'une fonction continue) ;
    \item[Structure d'une distribution tempérée :]  Une distribution tempérée est équivalent à la dérivée $\alpha^{\mbox{\small{ième}}}$ d'une fonction continue à croissance lente (\textit{i.e} qui ne croît pas plus vite que n'importe quel polynôme)
\end{description}
Notons que malgré que ces 2 théorèmes sont surtout à titre informatif étant donné qu'ils ne seront pas de grande utilité dans notre cours, ce sont tout de même des résultats importants qui peuvent souvent être très pratiques, 
sans même avoir pris connaissance de leur démonstration.

\subsection{Distributions tempérées}
Rappelons que les distributions tempérées agissent sur les fonctions test appartenant à l'ensemble $S$. \\
Afin de faciliter l'écriture, nous allons faire usage des notations suivantes : 
\begin{itemize}[label= \textbullet]
    \item $F \equiv$ Transformée de Fourier 
    \item $T \equiv$ forme linéaire $\in S$\textquotesingle  (dual de $S$) 
\end{itemize}
Rappelons également que $S$ est invariant sous $F$, autrement dit, la transformée de Fourier d'une fonction de $S$ est elle-même une fonction de $S$. \\
Nous allons étdendre la notion de transformée de Fourier sur des distributions tempérées. Cela va s'énoncer comme suit : \\
$\forall T \in S \mbox{\textquotesingle}$ ; $FT$, la transformée de Fourier de $T$, existe et est définie par :
\begin{equation}
\label{transformee de fourier de distribution}
    <FT, \phi> \mbox{ } = \mbox{ } <T, F\phi >
\end{equation}

\textit{Exemples :} \begin{itemize}[label= \textbullet]
    \item Si $f$ est une fonction, alors par \ref{transformee de fourier de distribution}, on a que : 
    \begin{align}
        <F T_f, \phi> \mbox{ } &= \mbox{ } <T_f, F \phi> \notag \\
        \implies \int dk \left( \int dx \frac{e^{-ikx}}{\sqrt{2\pi}}f(x) \right) \phi(k) &= \int dx f(x) \left( \int dk \frac{e^{-ikx}}{\sqrt{2\pi}}\Phi(k) \right)
    \end{align}
    \item $F \delta = \int_{\mathbb{R}} \delta(x) \frac{e^{-ikx}}{\sqrt{2 \pi}} dx = \frac{1}{\sqrt{2 \pi}} e^{-ik0} = \frac{1}{\sqrt{2 \pi}}$
    \item $F \delta \mbox{\textquotesingle} = ikF\delta = \frac{ik}{\sqrt{2 \pi}}$
\end{itemize}

\bg{Remarque :}{Le delta de Dirac est effectivement défini comme une distribution mais il faut savoir qu'en pratique : 
\begin{itemize}
    \item On manipule en réalité $\delta$ et ses dérivées comme si c'était des fonctions (telles que l'on connaît) ; 
    \item On utilise la définition suivante : $\delta(k) = \int dx \frac{e^{-ikx}}{2 \pi}$. Ceci nous permet de voir plus facilement cette distribution comme une fonction, et facilite certaines opérations. 
\end{itemize}
    }

\subsection{Delta de Dirac}
\begin{align}
\delta(x) &= \begin{cases}
+\infty \mbox{ en x = 0}\\
0 \mbox{ en } x\neq 0
\end{cases}		&\int^{+\infty}_{-\infty} dx \delta (x) = 1\\
\delta(x) &= \lim_{x\to 0} f_{\alpha}(x)	&\int^{+\infty}_{-\infty} dx f_\alpha (x) = 1
\end{align}
Où $f_\alpha (x)$ est strictement positif.
\begin{align}
\int_{-\infty}^{+\infty} dx f(x)\delta(x) &= f(0)\\
\int_{-\infty}^{+\infty} dx \delta(\Gamma - x)\delta(x- \zeta) &= \delta (\Gamma - \zeta)\\
\delta '(x) : \int^{+\infty}_{-\infty} \delta '(x)f(x) &= [\delta(x)f(x)]_{-\infty}^{+\infty} - \int_{-\infty}^{+\infty} dx \delta(x)f'(x)\\
&= -f'(0)\\
\int_{-\infty}^{+\infty} dx' \delta(x') &= \theta(x)		&\int dx f(x)\delta(x-a) = f(a)\\
\delta(\alpha x) &= \frac{1}{\norm{\alpha}}\delta(x)	&\delta(g(x)) = \frac{1}{\norm{g'(x_0)}}\delta(x-x_0)
\delta(-x) &= \delta(x)\\
\end{align}

\subsection{Transformée de Fourier d'une fonction périodique}
Si $x(t)$ est une fonction de période T tel que $x(t+T) = x(t)$. Alors $x(t)$ peut-être représenté comme une série de Fourier.
\begin{equation}
x(t) = \sum_{k = -\infty}^{+\infty} c_ke^{2\pi ik\frac{i}{T}}
\label{Z}
\end{equation}
Prenons la transformée de Fourier de \eqref{Z}.
\begin{align}
\hat{x} (\omega ) = \int dt \frac{e^{-i\omega t}}{\sqrt{2\pi}} x(t) &= \int_{k = -\infty}^{+\infty} c_k \int dt \frac{e^{-i\omega t}}{\sqrt{2\pi}}e^{2\pi i k \frac{t}{T}}\\
&= \sum_{k = -\infty}^{+\infty} \frac{c_k}{2\pi} \delta (\omega - \frac{2\pi k}{T})
\end{align}
Nous appelons $\hat{x}(\omega)$ est la somme des deltas espacés de $\frac{2\pi}{T}$.

\end{document}